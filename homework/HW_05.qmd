---
title: "Homework 5"
format: 
    html:
        embed-resources: true
---


__Due Date:__ 2024-11-20 at 8:30 AM PT
---


__Name:__ JJ Gluckman


## Preparation

1. We're using the same [data file](https://github.com/gabehassler/PRGS-Intro-to-ML-2024/blob/main/data/processed/svi_covid.csv) from GitHub as the last assignment.
If should be in the _data/processed_ folder.

The below section was generated by the GitHub chat agent after several hours of trying to get Tensorflow working on my RAND laptop.
```{r}
Sys.setenv(RETICULATE_PYTHON = "C:/r-tf/Scripts/python.exe")
#logfile <- "submit.log"
#sink(logfile, append = FALSE, split = TRUE)
rm(list=ls())

if(Sys.getenv("RETICULATE_PYTHON") == "") {
  Sys.setenv(RETICULATE_PYTHON = "C:/Users/jgluckman/AppData/Local/r-reticulate/r-reticulate/pyenv/pyenv-win/versions/3.11.9/python.exe")
} else {
   #cat("Using RETICULATE_PYTHON=", Sys.getenv("RETICULATE_PYTHON"), "\n")
  }
pacman::p_load(tidyverse, neuralnet, keras3, reticulate, tensorflow)
py_path <- Sys.getenv("RETICULATE_PYTHON")
if(py_path != "") {
  use_python(py_path, required = TRUE)
 } else {
   use_python("C:\\Users\\jgluckman\\AppData\\Local\\r-reticulate\\r-reticulate\\pyenv\\pyenv-win\\versions\\3.11.9\\python.exe", required=TRUE)  
}
setwd("C:\\Users\\jgluckman\\OneDrive - RAND Corporation\\Desktop\\Machine Learning\\PRGS-Intro-to-ML-2025\\")
data <- read.csv("data\\processed\\svi_covid.csv")
```

## Homework - Neural Newtorks

1. Use a simple neural network to predict the number of per-capita COVID-19 deaths in each county in the US using the SVI variables.
The outcome variable is `total_deaths_per_100k` and the predictor variables are `EP_POV150, EP_UNEMP, EP_HBURD, EP_NOHSDP, EP_UNINSUR, EP_AGE65, EP_AGE17, EP_DISABL, EP_SNGPNT, EP_LIMENG, EP_MINRTY, EP_MUNIT, EP_MOBILE, EP_CROWD, EP_NOVEH, EP_GROUPQ, EP_NOINT`.
The neural network should have one hidden layer with 10 nodes and use the ReLU activation function.
Plot the predicted values against the true values.
What is the mean squared error of the predictions in the test set?

```{r}
keep <- c("total_deaths_per_100k", "EP_POV150", "EP_UNEMP", "EP_HBURD", "EP_NOHSDP", "EP_UNINSUR", "EP_AGE65", "EP_AGE17", "EP_DISABL", "EP_SNGPNT", "EP_LIMENG", "EP_MINRTY", "EP_MUNIT", "EP_MOBILE", "EP_CROWD", "EP_NOVEH", "EP_GROUPQ", "EP_NOINT")
data <- data[,keep]
train.perc <- 0.8
train.size <- round(train.perc*nrow(data))
test.size <- nrow(data) - train.size
assigns <- sample(0:1, nrow(data), prob = c(train.perc, (1-train.perc)), replace = TRUE)
train.df <- data[assigns == 0,]
test.df <- data[assigns == 1,]
```

Additional Chat fix for Python package errors
```{r}
if(!"keras" %in% loadedNamespaces()) {
   tryCatch(library(keras), error = function(e) print(paste("Warning: could not load keras: ", conditionMessage(e), "\n")))
 }
if(!"tensorflow" %in% loadedNamespaces()) {
   tryCatch(library(tensorflow), error = function(e) print(paste("Warning: could not load tensorflow: ", conditionMessage(e), "\n")))
 }
 if(!exists("keras_model_sequential")) {
   if(exists("keras_model_sequential", where = asNamespace("keras"), inherits = FALSE)) {
     assign("keras_model_sequential", get("keras_model_sequential", envir = asNamespace("keras")), envir = .GlobalEnv)
   }
 }
```

I had to consult the Chat for advice on how to clean the data to fit into the neural net, but the actual implementation has been modified by me
```{r}
factors <- names(train.df)[2:ncol(train.df)]
train.x <- train.df[,factors]
test.x <- test.df[,factors]
train.y <- c(train.df$total_deaths_per_100k)
test.y <- c(test.df$total_deaths_per_100k)

mean.list <- sapply(train.x, mean)
sds <- sapply(train.x, sd)
train.xs <- scale(train.x, center = mean.list, scale = sds)
test.xs <- scale(test.x, center = mean.list, scale = sds)
```

Code continued, input structure suggested by Chat but designed and implemented by me
```{r}
model.a <- keras_model_sequential()
model.a %>% 
layer_dense(units = 10, activation = "relu") %>%
layer_dense(units = 1)
model.a %>% compile(optimizer = "adam", loss = "mse")
model.a %>% fit(x = train.xs, y = train.y, epochs = 100, batch_size = 32, validation_split = 0.2, verbose = 0)
```

Prediction segment also inspired by Chat but again designed by me
```{r}
preds <- model.a$predict(test.xs)
mse <- sum((preds-test.y)^2)/length(preds)
print(mse)

slope <- mean(test.y/preds)
ggplot() +
geom_point(aes(x = preds, y = test.y)) +
geom_abline(slope = slope) +
labs(title = "Predicted vs. Actual Values", x = "Predicted", y = "Actual")
```



2. Repeat the analysis from the previous question, but this time use a more complicated neural network with more hidden layers and/or more nodes in the hidden layers.
You should experiment with different architectures and activation functions to see what works best.
Plot the predicted values against the true values.
What is the mean squared error of the predictions in the test set?
```{r}
model.more.layers <- keras_model_sequential()
model.more.layers %>% layer_dense(units = 10, activation = "relu") %>% layer_dense(units = 10, activation = "relu") %>%  layer_dense(units = 10, activation = "relu") %>%  layer_dense(1)
model.more.layers %>% compile(optimizer = "adam", loss = "mse")
model.more.layers %>% fit(x = train.xs, y = train.y, epochs = 100, batch_size = 32, validation_split = 0.2, verbose = 0)

preds.b <- model.more.layers$predict(test.xs)
mse.b <- sum((preds.b-test.y)^2)/length(preds.b)
print(mse.b)

slope.b <- mean(test.y/preds.b)
ggplot() +
geom_point(aes(x = preds.b, y = test.y)) +
geom_abline(slope = slope.b) +
labs(title = "Predicted vs. Actual Values", subtitle = "More Layers", x = "Predicted", y = "Actual")
```


```{r}
model.more.nodes <- keras_model_sequential()
model.more.nodes %>% layer_dense(units = 15, activation = "relu") %>% layer_dense(1)
model.more.nodes %>% compile(optimizer = "adam", loss = "mse")
model.more.nodes %>% fit(x = train.xs, y = train.y, epochs = 100, batch_size = 32, validation_split = 0.2, verbose = 0)

preds.c <- model.more.nodes$predict(test.xs)
mse.c <- sum((preds.c-test.y)^2)/length(preds.c)
print(mse.c)

slope.c <- mean(test.y/preds.c)
ggplot() +
geom_point(aes(x = preds.c, y = test.y)) +
geom_abline(slope = slope.c) +
labs(title = "Predicted vs. Actual Values", subtitle = "More Nodes", x = "Predicted", y = "Actual")
```



```{r}
model.softmax <- keras_model_sequential()
model.softmax %>% layer_dense(units = 10, activation = "softmax") %>% layer_dense(1)
model.softmax %>% compile(optimizer = "adam", loss = "mse")
model.softmax %>% fit(x = train.xs, y = train.y, epochs = 100, batch_size = 32, validation_split = 0.2, verbose = 0)

preds.d <- model.softmax$predict(test.xs)
mse.d <- sum((preds.d-test.y)^2)/length(preds.d)
print(mse.d)

slope.d <- mean(test.y/preds.d)
ggplot() +
geom_point(aes(x = preds.d, y = test.y)) +
geom_abline(slope = slope.d) +
labs(title = "Predicted vs. Actual Values", subtitle = "Softmax", x = "Predicted", y = "Actual")
```


3. Compare the predictions of the neural network in Question 2 to the predictions of the regression tree from the previous assignment. Which model would you use to predict the number of per-capita COVID-19 deaths? Why?

Which model would you use to understand the relationship between the SVI variables and the number of per-capita COVID-19 deaths? Why?
Looking at my final results, I would rather use a neural network for the overall predictions. The decision tree bundled possible values based on its parting points, which reduces overall accuracy. However, for understanding the impact of the individual variables, the parts creating bundled results is more useful, as the splits are based on the most significant changes in the SVI variables.